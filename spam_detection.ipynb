{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7suMD7sVh2p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdzR_zGEW_c3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/spam.csv', encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x01F-20-ZGa1"
      },
      "outputs": [],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHLuM3BWZNoq"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpOcMZI0i4kG"
      },
      "source": [
        "##1. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stBuzmt2ipqO"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGOn061ojORo"
      },
      "outputs": [],
      "source": [
        "# drop last 3 cols\n",
        "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--ycRWdOjSqa"
      },
      "outputs": [],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMq_WBv7jYBp"
      },
      "outputs": [],
      "source": [
        "# renaming the cols\n",
        "df.rename(columns={'v1':'target','v2':'text'},inplace=True)\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUS5iPERjlRO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tJsgemOj51P"
      },
      "outputs": [],
      "source": [
        "df['target'] = encoder.fit_transform(df['target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b7D1T-Xj8wi"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ut5cnwmklg9"
      },
      "outputs": [],
      "source": [
        "# missing values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GvBpRWqkpqE"
      },
      "outputs": [],
      "source": [
        "# check for duplicate values\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XypoDMLxk3AQ"
      },
      "outputs": [],
      "source": [
        "# remove duplicates\n",
        "df = df.drop_duplicates(keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_huey9qVk-ah"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jnTAyuFlSa0"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85yfsh2ilkLo"
      },
      "source": [
        "##2. EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dIGhp68mNll"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLD76Rycllss"
      },
      "outputs": [],
      "source": [
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4we68IOl-gw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.pie(df['target'].value_counts(), labels=['ham','spam'],autopct=\"%0.2f\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xp5Vw7hobgF"
      },
      "outputs": [],
      "source": [
        "# Data is imbalanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQkViZUmpAPx"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpsinDEtqnhd"
      },
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxnuPgHlpE-x"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Download the punkt_tab resource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT_UHJ2rpPBe"
      },
      "outputs": [],
      "source": [
        "#num of characters\n",
        "df['num_characters'] = df['text'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1YqW3OmpQis"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G__mx-3FpwKF"
      },
      "outputs": [],
      "source": [
        "# num of words\n",
        "df['num_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLQRtbzVq_Ql"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSbbnFVgrDJU"
      },
      "outputs": [],
      "source": [
        "df['num_sentences'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGP-FfuWrHhz"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEPlbNaIrUEC"
      },
      "outputs": [],
      "source": [
        "df[['num_characters','num_words','num_sentences']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmJjLwxrre0g"
      },
      "outputs": [],
      "source": [
        "# ham\n",
        "df[df['target'] == 0][['num_characters','num_words','num_sentences']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8XD_9d9s-Nm"
      },
      "outputs": [],
      "source": [
        "# spam\n",
        "df[df['target'] == 1][['num_characters','num_words','num_sentences']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eylthfhgtG7y"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0ZRWvHviAyz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "sns.histplot(df[df['target'] == 0]['num_characters'])\n",
        "sns.histplot(df[df['target'] == 1]['num_characters'],color='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5njIMh6iwz8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "sns.histplot(df[df['target'] == 0]['num_words'])\n",
        "sns.histplot(df[df['target'] == 1]['num_words'],color='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcomMv8Pi7YM"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df,hue='target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATwpUvDXjJxc"
      },
      "outputs": [],
      "source": [
        "# Before calculating the correlation, select only numerical columns.\n",
        "numerical_df = df.select_dtypes(include=['number'])\n",
        "sns.heatmap(numerical_df.corr(),annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqE2Sz-TnJm_"
      },
      "source": [
        "\n",
        "##3. Data Preprocessing\n",
        "\n",
        "    Lower case\n",
        "    Tokenization\n",
        "    Removing special characters\n",
        "    Removing stop words and punctuation\n",
        "    Stemming\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjKNFvFGrZnT"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download the 'stopwords' dataset\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize the Porter Stemmer\n",
        "ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiI5P3UGnbfe"
      },
      "outputs": [],
      "source": [
        "\n",
        "def transform_text(text):\n",
        "    # Convert the text to lowercase to ensure uniformity\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize the text (split it into individual words)\n",
        "    text = nltk.word_tokenize(text)\n",
        "\n",
        "    y = []  # Temporary list to store processed words\n",
        "\n",
        "    # Remove non-alphanumeric characters (keep only words and numbers)\n",
        "    for i in text:\n",
        "        if i.isalnum():  # Check if the token is alphanumeric\n",
        "            y.append(i)\n",
        "\n",
        "    text = y[:]  # Copy filtered words back to text\n",
        "    y.clear()    # Clear the temporary list for the next step\n",
        "\n",
        "    # Remove stopwords (common words like 'the', 'is', etc.) and punctuation\n",
        "    for i in text:\n",
        "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
        "            y.append(i)\n",
        "\n",
        "    text = y[:]  # Copy filtered words back to text\n",
        "    y.clear()    # Clear the temporary list for the next step\n",
        "\n",
        "    # Apply stemming (reduce words to their root form)\n",
        "    for i in text:\n",
        "        y.append(ps.stem(i))\n",
        "\n",
        "    # Return the processed text as a single string, with words joined by spaces\n",
        "    return \" \".join(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmCWNNTrrWid"
      },
      "outputs": [],
      "source": [
        "transform_text(\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqqEhyw0tmZx"
      },
      "outputs": [],
      "source": [
        "df['transformed_text'] = df['text'].apply(transform_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir_KsJ5ltxyL"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBB1GAzkt3zm"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "wc = WordCloud(width=500,height=500,min_font_size=10,background_color='white')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp_PYiDvz801"
      },
      "outputs": [],
      "source": [
        "spam_wc = wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep=\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpxsqrvV0CJs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(spam_wc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzQxFEYo0K9y"
      },
      "outputs": [],
      "source": [
        "ham_wc = wc.generate(df[df['target'] == 0]['transformed_text'].str.cat(sep=\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn6Pv2z50Rne"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(ham_wc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8ESwG4_0WMG"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXSWEY_D0dTX"
      },
      "outputs": [],
      "source": [
        "spam_corpus = []  # Initialize an empty list to store spam words\n",
        "\n",
        "# Iterate through each message in the 'transformed_text' column where 'target' is 1 (spam)\n",
        "for msg in df[df['target'] == 1]['transformed_text'].tolist():\n",
        "\n",
        "    # Split the message into individual words and add them to spam_corpus\n",
        "    for word in msg.split():\n",
        "        spam_corpus.append(word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOHJQkb01jFJ"
      },
      "outputs": [],
      "source": [
        "print(spam_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h3H4ceQ2N4l"
      },
      "outputs": [],
      "source": [
        "len(spam_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yj4OwPbV2S8y"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Create a DataFrame from the Counter object\n",
        "spam_corpus_df = pd.DataFrame(Counter(spam_corpus).most_common(30), columns=['Word', 'Frequency'])\n",
        "\n",
        "# Use the DataFrame for the barplot\n",
        "sns.barplot(x='Word', y='Frequency', data=spam_corpus_df)\n",
        "\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Azz3PdBU4o3u"
      },
      "outputs": [],
      "source": [
        "ham_corpus = []\n",
        "for msg in df[df['target'] == 0]['transformed_text'].tolist():\n",
        "    for word in msg.split():\n",
        "        ham_corpus.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXPdqrYG4wX5"
      },
      "outputs": [],
      "source": [
        "len(ham_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGxICAEz5F7v"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Create a DataFrame from the Counter object\n",
        "ham_corpus_df = pd.DataFrame(Counter(ham_corpus).most_common(30), columns=['Word', 'Frequency'])\n",
        "\n",
        "# Use the DataFrame for the barplot\n",
        "sns.barplot(x='Word', y='Frequency', data=ham_corpus_df)\n",
        "\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02MFscKV6ahF"
      },
      "outputs": [],
      "source": [
        "# Text Vectorization\n",
        "# using Bag of Words\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clDulZXAPHt5"
      },
      "source": [
        "#4. Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuN01Qf6PMpe"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "cv = CountVectorizer()\n",
        "tfidf = TfidfVectorizer(max_features=3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97ss1ckebzsd"
      },
      "outputs": [],
      "source": [
        "X = tfidf.fit_transform(df['transformed_text']).toarray()\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb_0gbQAb4W7"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#scaler = MinMaxScaler()\n",
        "#X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymncxg5ocAZ-"
      },
      "outputs": [],
      "source": [
        "# appending the num_character col to X\n",
        "#X = np.hstack((X,df['num_characters'].values.reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kgl_I55WcEbZ"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc2V-URScKRU"
      },
      "outputs": [],
      "source": [
        "y = df['target'].values\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYgIOTodcV6t"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su3XGJaah8Bi"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOKaFhrwh_pH"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpUCw4ZTirgC"
      },
      "outputs": [],
      "source": [
        "gnb = GaussianNB()\n",
        "mnb = MultinomialNB()\n",
        "bnb = BernoulliNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oFX7K6vivje"
      },
      "outputs": [],
      "source": [
        "gnb.fit(X_train,y_train)\n",
        "y_pred1 = gnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred1))\n",
        "print(confusion_matrix(y_test,y_pred1))\n",
        "print(precision_score(y_test,y_pred1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5a5IBqflhC-"
      },
      "outputs": [],
      "source": [
        "mnb.fit(X_train,y_train)\n",
        "y_pred2 = mnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred2))\n",
        "print(confusion_matrix(y_test,y_pred2))\n",
        "print(precision_score(y_test,y_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKnuKZRRlpd6"
      },
      "outputs": [],
      "source": [
        "bnb.fit(X_train,y_train)\n",
        "y_pred3 = bnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred3))\n",
        "print(confusion_matrix(y_test,y_pred3))\n",
        "print(precision_score(y_test,y_pred3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9d1IxCwl3UZ"
      },
      "outputs": [],
      "source": [
        "# tfidf --> MNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5ftMHHnl-V2"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhvri7czmF8s"
      },
      "outputs": [],
      "source": [
        "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
        "knc = KNeighborsClassifier()\n",
        "mnb = MultinomialNB()\n",
        "dtc = DecisionTreeClassifier(max_depth=5)\n",
        "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
        "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
        "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
        "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
        "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
        "xgb = XGBClassifier(n_estimators=50,random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V4zya7YyPzq"
      },
      "outputs": [],
      "source": [
        "clfs = {\n",
        "    'SVC' : svc,\n",
        "    'KN' : knc,\n",
        "    'NB': mnb,\n",
        "    'DT': dtc,\n",
        "    'LR': lrc,\n",
        "    'RF': rfc,\n",
        "    'AdaBoost': abc,\n",
        "    'BgC': bc,\n",
        "    'ETC': etc,\n",
        "    'GBDT':gbdt,\n",
        "    'xgb':xgb\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1zw5eJzyYOU"
      },
      "outputs": [],
      "source": [
        "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test,y_pred)\n",
        "    precision = precision_score(y_test,y_pred)\n",
        "\n",
        "    return accuracy,precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0WGDr3my1i-"
      },
      "outputs": [],
      "source": [
        "train_classifier(svc,X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IP3UVcqzHB-"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists to store accuracy and precision scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "# Iterate through each classifier in the dictionary `clfs`\n",
        "for name, clf in clfs.items():  # `name` is the model's name, `clf` is the classifier instance\n",
        "\n",
        "    # Train the current classifier and get accuracy and precision scores\n",
        "    current_accuracy, current_precision = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Print the results for the current classifier\n",
        "    print(\"For \", name)\n",
        "    print(\"Accuracy - \", current_accuracy)\n",
        "    print(\"Precision - \", current_precision)\n",
        "\n",
        "    # Store accuracy and precision scores in their respective lists\n",
        "    accuracy_scores.append(current_accuracy)\n",
        "    precision_scores.append(current_precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA-t_7eL2lUN"
      },
      "outputs": [],
      "source": [
        "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng6oazDG22qe"
      },
      "outputs": [],
      "source": [
        "performance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBhNQEsZ29ac"
      },
      "outputs": [],
      "source": [
        "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")\n",
        "performance_df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Hfa55BW4jFO"
      },
      "outputs": [],
      "source": [
        "sns.catplot(x = 'Algorithm', y='value',\n",
        "               hue = 'variable',data=performance_df1, kind='bar',height=5)\n",
        "plt.ylim(0.5,1.0)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgNKDDmRSO1I"
      },
      "source": [
        "# model improvement\n",
        "# 1. Change the max_features parameter of TfIdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmKHX5S1SYR_"
      },
      "outputs": [],
      "source": [
        "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_max_ft_3000':accuracy_scores,'Precision_max_ft_3000':precision_scores}).sort_values('Precision_max_ft_3000',ascending=False)\n",
        "temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU6RBCLOSu8p"
      },
      "outputs": [],
      "source": [
        "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_scaling':accuracy_scores,'Precision_scaling':precision_scores}).sort_values('Precision_scaling',ascending=False)\n",
        "temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkhLxPwXS799"
      },
      "outputs": [],
      "source": [
        "new_df = performance_df.merge(temp_df,on='Algorithm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3pG3paOTQUn"
      },
      "outputs": [],
      "source": [
        "new_df_scaled = new_df.merge(temp_df,on='Algorithm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmR3-j67TYrL"
      },
      "outputs": [],
      "source": [
        "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_num_chars':accuracy_scores,'Precision_num_chars':precision_scores}).sort_values('Precision_num_chars',ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O2fxxbBUS1f"
      },
      "outputs": [],
      "source": [
        "new_df_scaled.merge(temp_df,on='Algorithm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UZxAln7UaER"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Defining individual classifiers\n",
        "svc = SVC(kernel='sigmoid', gamma=1.0, probability=True)\n",
        "mnb = MultinomialNB()\n",
        "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
        "\n",
        "# Creating a Voting Classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('svc', svc), ('mnb', mnb), ('etc', etc)],\n",
        "    voting='soft'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9ZUf9F8VHKb"
      },
      "outputs": [],
      "source": [
        "voting = VotingClassifier(estimators=[('svm', svc), ('nb', mnb), ('et', etc)],voting='soft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7iA0nY6VKAY"
      },
      "outputs": [],
      "source": [
        "voting.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbg4bH8lVdJa"
      },
      "outputs": [],
      "source": [
        "y_pred = voting.predict(X_test)\n",
        "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
        "print(\"Precision\",precision_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oNTMHREVi1L"
      },
      "outputs": [],
      "source": [
        "# Applying stacking\n",
        "estimators=[('svm', svc), ('nb', mnb), ('et', etc)]\n",
        "final_estimator=RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0NA_WOeVqJc"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrcVB-2CVtql"
      },
      "outputs": [],
      "source": [
        "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL5SpJlmVyfT"
      },
      "outputs": [],
      "source": [
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
        "print(\"Precision\",precision_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRPMfMf5W_hh"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(tfidf,open('vectorizer.pkl','wb'))\n",
        "pickle.dump(mnb,open('model.pkl','wb'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
